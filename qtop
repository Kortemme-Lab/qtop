#!/usr/bin/env python2
# -*- mode:python;show-trailing-whitespace:t; -*-

"""
Show which jobs are running on the cluster.

Usage:
    qtop [options]

Options:
    -u --user=NAME
        The name(s) of the user(s) to display information for.  By default, the
        user calling the program will be used.  Specify '*' to see all users.

    -p --project=NAME
        The name(s) of the project(s) to display information for.  By default,
        the projects that user calling the program belongs to will be used.
        Specify '*' to see all projects.

    -i
        Run the program in interactive mode, refreshing qstat data every
        interval seconds

    --interval=INTERVAL
        Number of seconds between interactive refreshes

    --test
        Instead of running qstat, parse from output files in the testing_output
        directory

"""

import subprocess, getpass, collections, itertools
import os
import time
import random
from Queue import Queue
from threading import Thread
from blessings import Terminal

class TermPrinter(object):
    def __init__(self):
        self.term = Terminal()
        self.string_queue = []

    def queue(self, string):
        self.string_queue.append( str(string) )

    def finalize(self):
        print self.term.clear()

        line_count = 0
        for string in self.string_queue:
            for split_string in string.split('\n'):
                if line_count == 0:
                    print self.term.move(0, 0) + split_string + self.term.clear_eol
                else:
                    print split_string + self.term.clear_eol
                line_count += 1

        self.string_queue = []

term_printer = TermPrinter()

def sh(cmd):
    """
    Run the given command in a shell.

    The command should be a single string containing a shell command.  If the
    command contains the names of any local variables enclosed in braces, the
    actual values of the named variables will be filled in.  (Note that this
    works on variables defined in the calling scope, which is a little bit
    magical.)  Regular braces must be escaped as you would with str.format().
    Also be aware that this approach is vulnerable to shell injection attacks.
    """

    # Figure out what local variables are defined in the calling scope.

    import inspect
    frame = inspect.currentframe()
    try: locals = frame.f_back.f_locals
    finally: del frame

    # Run the given command in a shell.  Return everything written to stdout if
    # the command returns an error code of 0, otherwise raise an exception.

    from subprocess import Popen, PIPE, CalledProcessError
    process = Popen(cmd.format(**locals), shell=True, stdout=PIPE)
    stdout, unused_stderr = process.communicate()
    retcode = process.poll()
    if retcode:
        error = subprocess.CalledProcessError(retcode, cmd)
        error.output = stdout
        raise error
    return stdout.strip()

def choose_user(user=None):
    if user is not None:
        return user
    else:
        import getpass
        return getpass.getuser()

def choose_project(project=None, user=None):
    if project is not None:
        return project
    else:
        user = choose_user(user)
        return sh('''\
                qconf -suser {user} |
                grep default_project |
                awk '{{print $2}}' ''')

class Task (object):
    # Each task will have many subtasks
    def __init__ (self, task_id, fields):
        self.id = task_id
        self.parse_task_fields(fields)
        self.basic_attrs_to_update = [
            'state', 'cpu', 'mem', 'io',
            'tckts', 'ovrts', 'otckt',
            'ftckt', 'stckt', 'share',
            'queue', 'slots',
        ]

    def parse_task_fields(self, fields):
        self.state = fields[7]

        if 'r' in self.state:
            self.cpu = fields[8]
            self.mem = fields[9]
            self.io = fields[10]
            self.tckts = fields[11]
            self.ovrts = fields[12]
            self.otckt = fields[13]
            self.ftckt = fields[14]
            self.stckt = fields[15]
            self.share = fields[16]
            self.queue = fields[17]
            self.slots = fields[18]

        else:
            self.cpu = None
            self.mem = None
            self.io = None
            self.tckts = fields[8]
            self.ovrts = fields[9]
            self.otckt = fields[10]
            self.ftckt = fields[11]
            self.stckt = fields[12]
            self.share = fields[13]
            self.queue = None
            self.slots = fields[14]

    def update(self, other):
        for attr in self.basic_attrs_to_update:
            setattr(self, attr, getattr(other, attr))

class Tasks (object):
    # Each job only holds one Tasks object, but it is split
    # apart for extra readability
    def __init__(self, fields):
        self.all_task_ids = set()
        self.recently_touched_task_ids = set()
        self.active_tasks = {} # Task IDs still appearing in output
        self.inactive_tasks = {} # No longer appearing in output
        self.parse_tasks_fields(fields)

    def parse_tasks_fields(self, fields):
        ja_task_id = fields[-1]

        if len(ja_task_id) > 0:
            new_task_ids = parse_ja_task_id(ja_task_id)
        else:
            new_task_ids = set()

        self.all_task_ids.update( new_task_ids )
        for task_id in new_task_ids:
            self.update_task( Task(task_id, fields) )

    def update_task(self, task):
        self.all_task_ids.add(task.id)
        self.recently_touched_task_ids.add(task.id)
        if task.id in self.active_tasks:
            self.active_tasks[task.id].update(task)
        elif task.id in self.inactive_tasks:
            self.active_tasks[task.id] = self.inactive_tasks[task.id]
            del self.inactive_tasks[task.id]
            self.active_tasks[task.id].update(task)
        else:
            self.active_tasks[task.id] = task

    def update(self, other):
        self.all_task_ids.update( other.all_task_ids )
        self.recently_touched_task_ids.update( other.recently_touched_task_ids )

        # Update active tasks dict
        for task_id, task in other.active_tasks.iteritems():
            if task_id in self.active_tasks:
                self.active_tasks[task_id].update(task)
            elif task_id in self.inactive_tasks:
                self.active_tasks[task.id] = self.inactive_tasks[task.id]
                del self.inactive_tasks[task.id]
                self.active_tasks[task.id].update(task)
            else:
                self.active_tasks[task_id] = task

        # Update inactive tasks dict
        for task_id, task in other.inactive_tasks.iteritems():
            if task_id in self.inactive_tasks:
                self.inactive_tasks[task_id].update(task)
            elif task_id in self.active_tasks:
                self.inactive_tasks[task.id] = self.active_tasks[task.id]
                del self.active_tasks[task.id]
                self.inactive_tasks[task.id].update(task)
            else:
                self.inactive_tasks[task_id] = task

    def mark_inactive_tasks(self):
        # Create a separate list of IDs ahead of time,
        # because we may delete some and modify the dict
        # as we go, which would break a direct iterator
        task_ids = self.active_tasks.keys()

        for task_id in task_ids:
            if task_id not in self.recently_touched_task_ids:
                task = self.active_tasks[task_id]
                del self.active_tasks[task_id]
                self.inactive_tasks[task_id] = task
        self.recently_touched_task_ids = set()

def parse_ja_task_id(ja_task_id):
    task_ids = set()
    for s in ja_task_id.split(','):
        if '-' in s:
            assert( ':' in s )
            range_str, step = s.strip().split(':')
            range_start, range_end = range_str.split('-')
            for x in xrange( int(range_start), int(range_end)+1, int(step) ):
                task_ids.add(x)
        else:
            task_ids.add( int(s) )

    return task_ids

class Job (object):
    def __init__(self, qstat_line):
        fields = qstat_line.split()
        try:
            self.parse_job_fields(fields)
        except:
            print 'Error parsing qstat line:'
            print '  ', qstat_line
            raise

        self.tasks = Tasks(fields)

        # When a job object is updated, these will all be copied
        # from the new job to this object
        self.basic_attrs_to_update = [
            'id', 'prior', 'ntckts', 'user', 'project',
            'department',
            'short_name'
        ]

        self.state = None
        self.full_name = None

    def parse_job_fields(self, fields):
        self.id = long(fields[0])
        self.prior = fields[1]
        self.ntckts = fields[2]
        self.name = fields[3]
        self.short_name = self.name
        self.user = fields[4]
        self.project = fields[5]
        self.department = fields[6]

    def update(self, other):
        for attr in self.basic_attrs_to_update:
            setattr(self, attr, getattr(other, attr))
        self.tasks.update(other.tasks)

    def set_qstat_data(self, qstat_data):
        self.qstat_data = qstat_data

        if 'job_name' in qstat_data:
            self.full_name = qstat_data['job_name']
            self.name = self.full_name

    def after_update(self):
        self.tasks.mark_inactive_tasks()

def enhance_job_data(job_id_queue, results_queue, testing_mode):
    while True:
        if not job_id_queue.empty():
            job_id = job_id_queue.get()

            if testing_mode:
                qstat_file = 'testing_output/job_specific_output/%d' % job_id
                if os.path.isfile(qstat_file):
                    with open(qstat_file, 'r') as f:
                        qstat_output = f.readlines()
                else:
                    qstat_output = None
            else:
                try:
                    qstat_output = sh('qstat -j %d' % job_id).split('\n')
                except:
                    qstat_output = None

            if qstat_output:
                qstat_data = {}
                for line in qstat_output[1:]:
                    fields = line.split(':')
                    if len(fields) == 2:
                        qstat_data[fields[0].strip()] = fields[1].strip()
                if len(qstat_data) > 0:
                    results_queue.put(qstat_data)
                    time.sleep(2.0) # Only run qstat -j every this n seconds
        else:
            time.sleep(0.1) # Check queue more often, as this is easy

class Jobs (object):
    def __init__(self, testing_mode, project):
        self.jobs = {}
        self.project = project
        self.test_iteration = 0
        self.testing_mode = testing_mode

        self.jobs_to_update = Queue()
        self.updated_jobs_results = Queue()
        self.job_data_updater = Thread(
            target = enhance_job_data,
            args = (
                self.jobs_to_update,
                self.updated_jobs_results,
                self.testing_mode)
        )
        self.job_data_updater.daemon = True
        self.job_data_updater.start()

        self.old_job_ids = set()

    def count_jobs_by_name(self, states, project=None, invert_logic=False):
        if not project:
            project = self.project

        count_dict = {}
        users = set()
        for job in self.jobs.values():
            if project and job.project != project:
                continue

            task_counts = {
                'lab_q_tasks' : 0,
                'long_q_tasks' : 0,
                'short_q_tasks' : 0,
            }
            def count_task(task, task_counts):
                if task.queue.startswith('lab.q'):
                    task_counts['lab_q_tasks'] += 1
                elif task.queue.startswith('long.q'):
                    task_counts['long_q_tasks'] += 1
                elif task.queue.startswith('short.q'):
                    task_counts['short_q_tasks'] += 1
                else:
                    raise Exception(
                        "Can't recognize task queue %s (job %d task %d)" % (task.queue, job.id, task.id)
                    )
                return task_counts

            for task in job.tasks.active_tasks.values():
                if invert_logic:
                    if task.state not in states:
                        task_counts = count_task(task, task_counts)
                else:
                    if task.state in states:
                        task_counts = count_task(task, task_counts)

            all_tasks = task_counts['lab_q_tasks'] + task_counts['short_q_tasks'] + task_counts['long_q_tasks']
            if all_tasks > 0:
                short_name = job.short_name
                user = job.user
                users.add(user)
                job_tup = (short_name, user)

                if job_tup in count_dict:
                    count_dict[job_tup]['jobs'] += 1
                    count_dict[job_tup]['all_tasks'] += all_tasks
                    count_dict[job_tup]['lab_q_tasks'] += task_counts['lab_q_tasks']
                    count_dict[job_tup]['short_q_tasks'] += task_counts['short_q_tasks']
                    count_dict[job_tup]['long_q_tasks'] += task_counts['long_q_tasks']
                    count_dict[job_tup]['full_names'].add(job.full_name)
                else:
                    count_dict[job_tup] = {
                        'jobs' : 1,
                        'all_tasks' : all_tasks,
                        'lab_q_tasks' : task_counts['lab_q_tasks'],
                        'short_q_tasks' : task_counts['short_q_tasks'],
                        'long_q_tasks' : task_counts['long_q_tasks'],
                        'full_names' : set([job.full_name]),
                    }

        # Process full names to be common string by position
        # It could be cool to make this instead add wildcards more fancily
        for job_tup, inner_dict in count_dict.iteritems():
            if None in inner_dict['full_names']:
                inner_dict['full_names'].remove(None)

            if len(inner_dict['full_names']) == 0:
                inner_dict['common_full_name'] = job_tup[0]
                continue

            full_names = [
                y for x, y in sorted(
                    [(len(name), name) for name in inner_dict['full_names']
                 ], reverse=True )
            ]

            common_full_name = ''
            for i, char in enumerate(full_names[0]):
                add_char = True
                for full_name in full_names[1:]:
                    if len(full_name) <= i or char != full_name[i]:
                        add_char = False
                if add_char:
                    common_full_name += char
                elif common_full_name[-1] != '*':
                    common_full_name += '*'

            inner_dict['common_full_name'] = common_full_name

        return_list = []
        for job_tup in count_dict:
            job_short_name, job_user = job_tup
            return_list.append( (
                count_dict[job_tup]['all_tasks'],
                count_dict[job_tup]['jobs'],
                count_dict[job_tup]['lab_q_tasks'],
                count_dict[job_tup]['long_q_tasks'],
                count_dict[job_tup]['short_q_tasks'],
                job_user,
                count_dict[job_tup]['common_full_name'],
            ) )

        return_list.sort(reverse=True)
        self.counted_users = users
        return return_list

    def running(self, project=None):
        # TODO: return a list of lists, each row is current output
        # Each listrow is data for columns
        # Columns: Number of jobs (with equal names), number of tasks (total), script name
        return self.count_jobs_by_name(['r'], project=project)

    def queued(self, project=None):
        return self.count_jobs_by_name(['qw'], project=project)

    def remaining(self, project=None):
        return self.count_jobs_by_name(['r', 'qw'], project=project, invert_logic=True)

    def num_users(self, project=None):
        if not project:
            project = self.project

        users = set()
        for job in self.jobs.values():
            if project and job.project != project:
                continue
            users.add(job.user)
        return len(users)

    def update(self):
        if self.testing_mode:
            input_data = read_from_test_output(self.test_iteration)
            self.test_iteration += 1
        else:
            input_data = sh('qstat -ext -u \\*').split('\n')

        new_job_ids = set()
        parsed_job_ids = set()
        for line in input_data[2:]:
            job = Job(line)
            parsed_job_ids.add(job.id)
            if job.id in self.jobs:
                self.jobs[job.id].update(job)
            else:
                self.jobs[job.id] = job
                new_job_ids.add(job.id)

        missing_job_ids = self.old_job_ids.difference(parsed_job_ids)
        for job_id in missing_job_ids:
            assert( job_id in self.jobs )
            self.jobs[job_id].state = 'finished'
        self.old_job_ids = parsed_job_ids

        new_job_ids_list = list(new_job_ids)
        random.shuffle(new_job_ids_list)
        for job_id in new_job_ids_list:
            job = self.jobs[job_id]
            if job.project == self.project and len(job.name) >= 10:
                self.jobs_to_update.put(job_id)

        # Get new qstat_data results from queue
        while not self.updated_jobs_results.empty():
            qstat_data = self.updated_jobs_results.get()
            job_id = long( qstat_data['job_number'] )
            self.jobs[job_id].set_qstat_data( qstat_data )

        # Mark inactive tasks
        for job in self.jobs.values():
            job.after_update()

    def __iter__(self):
        self.sorted_job_ids = [
            x for x,y in self.jobs.iteritems() if y.state != 'finished'
        ]
        self.sorted_job_ids.sort(reverse=True)
        return self

    # Python 3 compatibility
    def __next__(self):
        return self.next()

    def next(self):
        if len(self.sorted_job_ids) == 0:
            raise StopIteration
        return self.jobs[ self.sorted_job_ids.pop() ]

def read_from_test_output(test_iteration):
    testing_output_dir = 'testing_output'
    assert( os.path.isdir( testing_output_dir ) )
    test_files = [
        os.path.join(testing_output_dir, f)
        for f in sorted(os.listdir(testing_output_dir))
        if 'job_specific_output' not in f
    ]

    term_printer.queue( test_files[test_iteration % len(test_files)] )
    with open(test_files[test_iteration % len(test_files)], 'r') as f:
        return f.readlines()

def display(data):
    max_lengths = []
    strings_to_print = []
    for i, l in enumerate(data):
        strings_to_print.append([])
        for j, s in enumerate(l):
            s = str(s)
            strings_to_print[i].append(s)
            s_len = len(s)
            while len(max_lengths) < j+1:
                max_lengths.append(0)
            if s_len > max_lengths[j]:
                max_lengths[j] = s_len

    for row in strings_to_print:
        row_str = ''
        for i, x in enumerate(row):
            row_str += '%s ' % x.ljust(max_lengths[i])
        term_printer.queue(
            row_str[:-1] # Remove trailing space
        )

def display_running_jobs(jobs):
    running_jobs = jobs.running()

    if jobs.project:
        term_printer.queue( "Currently running jobs by {0} {1} users:".format( len(jobs.counted_users), jobs.project ) )
    else:
        term_printer.queue( "Currently running jobs by {0} users:".format( len(jobs.counted_users) ) )

    display_list = [ [
        'Tasks', 'jobs',
        'lab.q', 'long.q', 'short.q',
        'User', 'Name',
    ] ]

    display_list.extend( running_jobs )
    display( display_list )

    term_printer.queue('') # spacer line

def display_queued_jobs(jobs):
    # filter = lambda j: j.state == 'qw'
    # display = '{count:>7d} {job.user:12} {job.name} ({job.ja_task_id})'

    queued_jobs = jobs.queued()
    # display_jobs(jobs, filter, display)
    term_printer.queue( "Currently queued jobs by {0} users:".format(len(jobs.counted_users)) )
    # display_jobs(jobs, lambda j: filter(j) and j.project == jobs.project, display)

    display( queued_jobs )

    term_printer.queue('') # spacer line


def display_remaining_jobs(jobs):
    # filter = lambda j: j.state not in ('r', 'qw')
    # display = '{count:>7d} {job.user:12} {job.name} ({job.state})'

    # display_jobs(jobs, filter, display)
    term_printer.queue( "Remaining jobs by {0} users:".format(jobs.num_users()) )
    # display_jobs(jobs, lambda j: filter(j) and j.project == jobs.project, display)

    display( jobs.remaining(project) )

def run( project, testing_mode=False, interval=0 ):
    # Figure out what projects to display information for.  If the user
    # specifies one or more projects on the command line, use them.  Otherwise
    # use the projects the current user belongs to.

    jobs = Jobs(testing_mode, project)
    while True:
        jobs.update()

        term_printer.queue( time.strftime("%a, %d %b %Y %H:%M:%S ") )
        display_running_jobs(jobs)
        # display_queued_jobs(jobs)
        # display_remaining_jobs(jobs)
        term_printer.finalize()

        if float(interval) == 0.0:
            return
        else:
            # Let's rest this thread
            time.sleep(float(interval))

if __name__ == '__main__':
    import docopt
    args = docopt.docopt(__doc__)

    testing_mode = args['--test']
    interactive_mode = args['-i']
    project = choose_project(args['--project'])
    args_interval = args['--interval']

    if not interactive_mode and not args_interval:
        interval = 0.0
    elif interactive_mode and not args_interval:
        interval = 10.0
    elif args_interval:
        interval = float( args_interval )

    run( project, testing_mode=testing_mode, interval=interval )
